import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data.dataset import Dataset
import os
import numpy as np
import joblib
# Local import 
from nidl.data.fetcher import download_file_with_progress_bar


class SyntheticDataset(Dataset):
    """Generate a synthetic dataset with the chosen generative process p(z|u)p(x|z) where u is a 
    continuous variable, z is a 2d Gaussian variable and x is the observed variable (`n_dim` dimensions). 
    
    Adapted from pi-VAE: https://github.com/zhd96/pi-vae/blob/main/code/pi_vae.py.

    This code is written in PyTorch for efficiency and simplicity.
    """

    def __init__(self, path: str="data/synthetic",
                  n_samples: int=15000, 
                  n_dim: int=100,
                  target: str="latent",
                  from_cebra: bool=True):
        """
        Args:
            path: Path where the data should be retrieved. 
                If no data are found or `from_cebra` is False , they are re-generated. 
            n_samples: The number of simulated samples.
                Ignored if data are already generated or `from_cebra` is True. 
            n_dim: The dimension of the observation. 
                Ignored if data are already generated or `from_cebra` is True.
            target: str in {"latent", "aux_var"} or None
                What target to return in __getitem__ for each sample:
                * If target=="latent", returns the 2d latent variable `z`
                * If target=="aux_var", returns the 1d auxiliary variable `u`
                * If target is None, don't return any target.
            from_cebra: boolean
                If True, downloads the data directly from CEBRA repository.
        """
        super().__init__()
        self.path = path
        self.from_cebra = from_cebra
        self.data = self._get_data()
        self.n_samples = n_samples
        self.target = target

        if self.data is None:
            print(f"Data not found. {n_samples} samples are generated (with dimension {n_dim}).")
            z_true, u_true, x = self.simulate_cont_data_diff_var(n_samples, n_dim)
            self.data = {"z_true": z_true, "u_true": u_true, "x": x}
            os.makedirs(path, exist_ok=True)
            np.savez(os.path.join(path, "continuous_label_poisson.npz"), **self.data)
            print(f"Data successfully generated and saved in {path}")
        else:
            n_true = len(self.data["x"])
            self.n_samples = n_true
            self.n_dim = self.data["x"].shape[1]


    def __getitem__(self, index: int):
        if self.target == "latent":
            return self.data["x"][index].astype(np.float32), self.data["z_true"][index]
        elif self.target == "aux_var":
            return self.data["x"][index].astype(np.float32), self.data["u_true"][index]
        elif self.target is None:
            return self.data["x"][index].astype(np.float32)
        else:
            raise ValueError(f"Unknown target: {self.target}")
    
    def _get_data(self):
        f = os.path.join(self.path, "continuous_label_poisson.npz")
        data = None

        if self.from_cebra:
            name = "continuous_label_poisson.jl"
            download_file_with_progress_bar(
                "https://figshare.com/ndownloader/files/41668827?private_link=7439c5302e99db36eebb",
                "a789828f9cca5f3faf36d62ebc4cc8a1",
                self.path,
                name
            )
            data = joblib.load(os.path.join(self.path, name))
            data = {"x": data["x"], "z_true": data["z"][:, :2], "u_true": data["u"]}
            
        elif os.path.isfile(f):
            data = np.load(f)
            # Load the data in memory
            data = {"x": data["x"], "z_true": data["z_true"], "u_true": data["u_true"]}
        return data

    def simulate_cont_data_diff_var(self, n_samples: int, n_dim: int):
        """Generate a synthetic dataset with the chosen generative process.

        Adapted from pi-VAE; https://github.com/zhd96/pi-vae/blob/main/code/pi_vae.py.
        The 1D continuous label u is sampled from uniform distribution defined in [0, 2*pi].
        The corresponding 2D latent z is sampled from a normal distribution defined by the mean (u, 2*sin(u)) 
        and the variance (0.6-0.3*|sin(u)|, 0.3*|sin(u)|).
        The n-dimensional firing rates are generated by feeding z into bijective mixing function modeled by RealNVP.
        Finally, observations x are generated by sampling Poisson distribution with the previous firing rates as mean.

        Args:
            n_samples: The number of simulated samples.
            n_dim: The dimension of the observation.
        Returns:
            z_true, u_true, x: Tuple (array, array, array), shape (n_samples, 2), (n_samples,), (n_samples, n_dim)
        """
        # Seed everything for reproducibility
        np.random.seed(777)

        # Sample continuous label u
        u_true = np.random.uniform(0, 2 * np.pi, size=[n_samples, 1])

        # Sample gaussian variable z
        mu_true = np.hstack((u_true, 2 * np.sin(u_true)))
        var_true = 0.15 * np.abs(mu_true)
        var_true[:, 0] = 0.6 - var_true[:, 1]
        z_true = np.random.normal(0, 1, size=[n_samples, 2]) * np.sqrt(var_true) + mu_true

        # Map high-dimensional firing rate from z through RealNVP network (bijective mapping)
        x = torch.hstack((torch.from_numpy(z_true), torch.zeros((n_samples, n_dim - 2)))).float()
        permute_ind = []
        n_blk = 4
        for i in range(n_blk):
            np.random.seed(i)
            permute_ind.append(np.random.permutation(n_dim))

        realnvp_blocks = [RealNVPBlock(n_dim, n_layers=2) for _ in range(n_blk)]

        x = realnvp_blocks[0](x)
        for i in range(n_blk - 1):
            x = x[:, permute_ind[i]]
            x = realnvp_blocks[i+1](x)
        x = np.exp(2.2 * np.tanh(x.detach().cpu().numpy()))

        # Generate high-dimensional Poisson samples from these firing rates
        x = np.random.poisson(x)
        return z_true, u_true, x
    
    def __len__(self):
        return self.n_samples


class RealNVPBlock(nn.Module):
    def __init__(self, n_dim: int, n_layers: int=2):
        """
        RealNVP block including `n_layers` layers for an input tensor of `n_dim` dimensions.
            Args:
                n_dim: Dimension of the input tensor. Must be an even number.
                n_layers: Number of layers.
        """
        super(RealNVPBlock, self).__init__()
        self.block = nn.Sequential(*[RealNVPLayer(n_dim) for _ in range(n_layers)])
    
    def forward(self, x):
        return self.block(x)


class RealNVPLayer(nn.Module):
    def __init__(self, n_dim: int):
        """
        RealNVP layer implementation.
        Args:
            n_dim: Dimension of the input tensor. Must be an even number.
        """
        super(RealNVPLayer, self).__init__()
        assert n_dim % 2 == 0, "Input dimension must be even"
        self.n_dim = n_dim
        self.half_dim = n_dim // 2

        # Define the dense layers for s and t functions
        self.dense1 = nn.Linear(self.half_dim, self.half_dim // 2)
        self.dense2 = nn.Linear(self.half_dim // 2, self.half_dim // 2)
        self.dense3 = nn.Linear(self.half_dim // 2, self.n_dim)

    def forward(self, x_input):
        """
        Args:
            x_input: Input tensor of shape (n_samples, n_dim).
        Returns:
            Output tensor of shape (n_samples, n_dim).
        """
        # Split the input into two halves
        x_input1 = x_input[:, :self.half_dim]
        x_input2 = x_input[:, self.half_dim:]

        # Compute s and t using dense layers
        st_output = F.relu(self.dense1(x_input1))
        st_output = F.relu(self.dense2(st_output))
        st_output = self.dense3(st_output)

        # Split s and t from the output
        s_output = st_output[:, :self.half_dim]
        t_output = st_output[:, self.half_dim:]

        # Clamp s_output to keep values small
        s_output = 0.1 * torch.tanh(s_output)

        # Perform the transformation
        trans_x = x_input2 * torch.exp(s_output) + t_output

        # Concatenate transformed x with the original x_input1
        output = torch.cat([trans_x, x_input1], dim=-1)

        return output


if __name__ == "__main__":
    dataset = SyntheticDataset()

